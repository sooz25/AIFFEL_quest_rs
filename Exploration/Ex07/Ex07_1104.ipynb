{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8793f38d-4d20-4b9a-90c5-88484a543c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588587df-cb2b-497f-a3ac-e717731fab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-04 07:24:31--  https://github.com/songys/Chatbot_data/raw/master/ChatbotData.csv\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv [following]\n",
      "--2025-11-04 07:24:32--  https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 889842 (869K) [text/plain]\n",
      "Saving to: â€˜ChatbotData.csvâ€™\n",
      "\n",
      "ChatbotData.csv     100%[===================>] 868.99K  5.29MB/s    in 0.2s    \n",
      "\n",
      "2025-11-04 07:24:32 (5.29 MB/s) - â€˜ChatbotData.csvâ€™ saved [889842/889842]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ~/work/transformer_chatbot/data/ && cd ~/work/transformer_chatbot/data/\n",
    "! wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a80976-48fd-43fe-920c-44fd5f19c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118 True\n"
     ]
    }
   ],
   "source": [
    "# í´ë”/íŒ¨í‚¤ì§€ ì¤€ë¹„\n",
    "!pip -q install transformers==4.43.3 accelerate sentencepiece datasets\n",
    "import os, pandas as pd, torch, numpy as np\n",
    "print(torch.__version__, torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af7b23f3-ece2-4faa-9ebe-b2dfbd397a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11740,\n",
       "               Q            A\n",
       " 0        12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.\n",
       " 1   1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.\n",
       " 2  3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° í™•ì¸ ë° ì •ë¦¬\n",
    "\n",
    "import pandas as pd, re\n",
    "path = os.path.expanduser('~/work/transformer_chatbot/data/ChatbotData.csv')\n",
    "df = pd.read_csv(path)\n",
    "df = df.rename(columns={df.columns[0]:'Q', df.columns[1]:'A'})  # ì•ˆì „í•˜ê²Œ\n",
    "df = df[['Q','A']].dropna().drop_duplicates()\n",
    "\n",
    "# ê°„ë‹¨ í´ë¦°ì—…(ì´ëª¨ì§€/ì´ìƒë¬¸ì ì œê±°Â·ì—°ì† ê³µë°± ì¶•ì†Œ)\n",
    "def clean(s):\n",
    "    s = re.sub(r'[^\\S\\r\\n]+', ' ', str(s)).strip()\n",
    "    s = re.sub(r'[\\u200b-\\u200f]', '', s)\n",
    "    return s\n",
    "df['Q'] = df['Q'].map(clean)\n",
    "df['A'] = df['A'].map(clean)\n",
    "\n",
    "# ê¸¸ì´ í•„í„°(ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸´ ìŒ ì œê±°)\n",
    "df = df[(df['Q'].str.len().between(2, 100)) & (df['A'].str.len().between(2, 120))]\n",
    "len(df), df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c59d81-f638-45dc-b36d-f35dd4f0b786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11153, 587)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµ/ ê²€ì¦ ë¶„ë¦¬\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(df, test_size=0.05, random_state=42, shuffle=True)\n",
    "len(train_df), len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39554ba-c243-43ab-a9ec-908bcf8e8d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0f9c4818a24446b4bc3f8b5f45b41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e3ef46efd34ad6a2962cbc00170535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae85180884042b3a4afcb6bda6ab4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) í† í¬ë‚˜ì´ì €/ëª¨ë¸ (KoGPT2)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "SEP = \"<unused0>\"   # KoGPT2ì— ë‚¨ëŠ” unused í† í° í•˜ë‚˜ë¥¼ êµ¬ë¶„ìë¡œ ì‚¬ìš©\n",
    "bos, eos, pad = tok.bos_token, tok.eos_token, tok.pad_token or \"<pad>\"\n",
    "\n",
    "if tok.pad_token is None:\n",
    "    tok.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "    model.resize_token_embeddings(len(tok))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db8d513c-452d-4fc0-9fb3-d32cedeb89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11153, 587)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4) ë°ì´í„°ì…‹/ì½œë ˆì´í„°\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, frame, tokenizer, max_len=128):\n",
    "        self.q = frame['Q'].tolist()\n",
    "        self.a = frame['A'].tolist()\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self): return len(self.q)\n",
    "    def __getitem__(self, i):\n",
    "        q, a = self.q[i], self.a[i]\n",
    "        text = f\"{bos}{q}{SEP}{a}{eos}\"\n",
    "        enc = self.tok(text, truncation=True, max_length=self.max_len, return_tensors=None)\n",
    "        # ë ˆì´ë¸” ë§ˆìŠ¤í‚¹: SEP ì´ì „ê¹Œì§€ -100\n",
    "        ids = enc['input_ids']\n",
    "        sep_id = self.tok.convert_tokens_to_ids(SEP)\n",
    "        try:\n",
    "            sep_pos = ids.index(sep_id)\n",
    "        except ValueError:\n",
    "            sep_pos = len(ids)//2  # í˜¹ì‹œ ëª» ì°¾ìœ¼ë©´ ëŒ€ì¶© ì ˆë°˜(ëª…ì‹œì  ê°€ì •)\n",
    "        labels = [-100]* (sep_pos+1) + ids[sep_pos+1:]\n",
    "        labels = labels[:self.max_len]\n",
    "        ids = ids[:self.max_len]\n",
    "        attn = [1]*len(ids)\n",
    "        # íŒ¨ë”©\n",
    "        pad_id = self.tok.pad_token_id\n",
    "        while len(ids) < self.max_len:\n",
    "            ids.append(pad_id); attn.append(0); labels.append(-100)\n",
    "        return {\"input_ids\": torch.tensor(ids), \"attention_mask\": torch.tensor(attn), \"labels\": torch.tensor(labels)}\n",
    "\n",
    "train_ds = ChatDataset(train_df, tok)\n",
    "valid_ds = ChatDataset(valid_df, tok)\n",
    "len(train_ds), len(valid_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7c78b3-add1-4f88-ba1b-6a044235b568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2091' max='2091' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2091/2091 09:36, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.633000</td>\n",
       "      <td>2.530363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.780300</td>\n",
       "      <td>2.223514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.117900</td>\n",
       "      <td>2.032925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>1.985633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2091, training_loss=1.8864070978078016, metrics={'train_runtime': 577.7543, 'train_samples_per_second': 57.912, 'train_steps_per_second': 3.619, 'total_flos': 2184532033536000.0, 'train_loss': 1.8864070978078016, 'epoch': 2.9978494623655916})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµ\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"kogpt2-chatbot\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=train_ds, eval_dataset=valid_ds)\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dabf1923-5bf5-45c4-bbf7-69517240a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§ˆìŒì˜ ì•ˆì •ì„ ì·¨í•˜ê¸° ì¢‹ì€ ë‚ ì´ì£ .\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜\n",
    "\n",
    "@torch.no_grad()\n",
    "def chat(prompt, max_new_tokens=64, top_p=0.9, temperature=0.8):\n",
    "    model.eval()\n",
    "    x = f\"{bos}{prompt}{SEP}\"\n",
    "    inp = tok(x, return_tensors=\"pt\").to(model.device)\n",
    "    out = model.generate(\n",
    "        **inp,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        top_p=top_p,\n",
    "        temperature=temperature,\n",
    "        pad_token_id=tok.pad_token_id,\n",
    "        eos_token_id=tok.eos_token_id\n",
    "    )\n",
    "    text = tok.decode(out[0], skip_special_tokens=False)\n",
    "    # SEP ì´í›„ë¶€í„° eos ì „ê¹Œì§€ ì˜ë¼ë‚´ê¸°\n",
    "    try:\n",
    "        ans = text.split(SEP,1)[1]\n",
    "    except:\n",
    "        ans = text\n",
    "    ans = ans.replace(tok.eos_token or \"</s>\", \"\").replace(tok.bos_token or \"<s>\", \"\").strip()\n",
    "    return ans\n",
    "\n",
    "print(chat(\"ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì¢€ ìš°ìš¸í•œë° ë­ í•˜ë©´ ì¢‹ì„ê¹Œ?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c81aa9-2273-4149-a52c-aafb80d39ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('kogpt2-chatbot/best/tokenizer_config.json',\n",
       " 'kogpt2-chatbot/best/special_tokens_map.json',\n",
       " 'kogpt2-chatbot/best/vocab.json',\n",
       " 'kogpt2-chatbot/best/merges.txt',\n",
       " 'kogpt2-chatbot/best/added_tokens.json',\n",
       " 'kogpt2-chatbot/best/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) ì €ì¥ & ë¡œë“œ\n",
    "\n",
    "trainer.save_model(\"kogpt2-chatbot/best\")\n",
    "tok.save_pretrained(\"kogpt2-chatbot/best\")\n",
    "# ë¡œë“œ\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"kogpt2-chatbot/best\"); tok = AutoTokenizer.from_pretrained(\"kogpt2-chatbot/best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd542d90-f4c3-42c5-8e6a-a40df160f604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§›ìˆëŠ” ê±° ë“œì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ì˜¤ëŠ˜ ì €ë…ì— ë­˜ ë¨¹ì„ê¹Œ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "154b19a3-14f3-4c09-92c5-e73e05149b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ë§ˆìŒì„ ì´ì–´ì£¼ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ë„ˆëŠ” ëˆ„êµ¬ì•¼?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc6cb97-691c-49c8-b347-311a62785f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ìœ„ë¡œë´‡ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ë‹¤ë¥¸ ì´ë¦„ì€ ì—†ì–´?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae87e6b-2d3a-447e-9511-eeedd4d5aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¨¼ì € ê´€ì‹¬ì‚¬ë¥¼ ì•Œì•„ë³´ê³  ê¸°ìˆ ì„ ì•Œì•„ë³´ëŠ”ê²Œ ìš°ì„ ì´ì—ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"aiëŠ” ì–´ë–»ê²Œ ê³µë¶€í•˜ëŠ”ê²Œ ì¢‹ì•„?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1354035-79bf-4e2e-be66-4951b0c8bb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§ì´ í˜ë“¤ì–´ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ì–´ë ¤ì›Œ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac276a12-e2e6-4748-ab80-eec4df2e4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆì§ˆ ëŒì§€ ë§ˆì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ë„¤ ëŒ€ë‹µì˜ ì •í™•ë„ëŠ”?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4a76be6-83ef-41ff-b410-66c9cad8389d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ë‹µì´ ì—†ì–´ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ì–´ë–¤ ì§ˆë¬¸ì´ ê°€ëŠ¥í•´?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0abeaf33-40d9-427b-b4d1-fc36e24bc68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê·¸ ì¤‘ì— ë§ˆìŒì— ë“œëŠ” ê±´ ì‚¬ì¤„ ê±°ì˜ˆìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"Qì˜ ë‚´ìš©ì´ ì´ ëª‡ê°€ì§€ê°€ ìˆì–´?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

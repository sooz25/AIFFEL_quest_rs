{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e35e502-adde-4400-b264-5c4cbcfdf00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 0. 기본 설정 & 하이퍼파라미터\n",
    "#############################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# node4에서 쓰던 이미지 폴더 경로로 맞춰줘\n",
    "dataset_dir = \"~/work/data_augmentation/data/Images/\"\n",
    "\n",
    "# 메모리·시간 고려해서 작은 값으로 시작\n",
    "BATCH_SIZE = 32       # 필요하면 2로 줄여도 됨\n",
    "EPOCHS = 10           # 먼저 2ep로 테스트 → 나중에 5, 10으로 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7073cbed-8874-4bf5-a4f9-99e4fc33620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 개수: 120\n",
      "DataLoaders ready.\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 1. Dataset / Transform 정의\n",
    "#############################################\n",
    "\n",
    "# (1) 기본 전처리: Resize + ToTensor + Normalize\n",
    "def normalize_and_resize_img():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((128, 128)),   # 224x224 → 128x128로 줄여서 가볍게\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "# (2) 기본 Augmentation: 좌우반전 + 밝기조절\n",
    "def basic_augment():\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2),\n",
    "    ])\n",
    "\n",
    "# (3) ImageFolder로 전체 데이터 불러오기 (transform은 나중에 쓸 거라 None)\n",
    "full_dataset = ImageFolder(root=dataset_dir, transform=None)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.583 * total_size)  # node4 비율\n",
    "val_size = total_size - train_size\n",
    "ds_train, ds_val = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "NUM_CLASSES = len(full_dataset.classes)\n",
    "print(\"클래스 개수:\", NUM_CLASSES)\n",
    "\n",
    "# (4) 하나의 Subset(ds_train)을 서로 다른 transform으로 감싸기 위한 래퍼\n",
    "class WrappedSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]   # img: PIL.Image, label: int\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# (5) transform 조합 만들기\n",
    "base_transform = normalize_and_resize_img()\n",
    "aug_transform = transforms.Compose([\n",
    "    *basic_augment().transforms,\n",
    "    *base_transform.transforms,\n",
    "])\n",
    "\n",
    "# (6) 4가지 실험 중 “데이터셋 관점”에서는 2가지:\n",
    "#   - No Aug: base_transform만 사용\n",
    "#   - Basic Aug: aug_transform 사용\n",
    "train_noaug_ds = WrappedSubset(ds_train, transform=base_transform)\n",
    "train_basic_ds = WrappedSubset(ds_train, transform=aug_transform)\n",
    "val_ds        = WrappedSubset(ds_val,   transform=base_transform)\n",
    "\n",
    "train_loader_noaug = DataLoader(train_noaug_ds,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0)  # CPU 환경이니 0으로\n",
    "train_loader_basic = DataLoader(train_basic_ds,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0)\n",
    "val_loader = DataLoader(val_ds,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0)\n",
    "\n",
    "print(\"DataLoaders ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8149e358-ae29-4419-8a74-5f37188da3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2. MixUp / CutMix + Loss\n",
    "#############################################\n",
    "\n",
    "def onehot(labels, num_classes=NUM_CLASSES):\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        return torch.nn.functional.one_hot(labels, num_classes=num_classes).float()\n",
    "    else:\n",
    "        return torch.nn.functional.one_hot(torch.tensor(labels),\n",
    "                                           num_classes=num_classes).float()\n",
    "\n",
    "def categorical_crossentropy(logits, target_onehot):\n",
    "    \"\"\"\n",
    "    logits: (B, C), target_onehot: (B, C)\n",
    "    MixUp/CutMix 같이 soft label일 때 쓰는 loss\n",
    "    \"\"\"\n",
    "    log_probs = torch.log_softmax(logits, dim=1)\n",
    "    loss = -(target_onehot * log_probs).sum(dim=1).mean()\n",
    "    return loss\n",
    "\n",
    "def mixup_batch(x, y, alpha=1.0, num_classes=NUM_CLASSES):\n",
    "    if alpha <= 0:\n",
    "        return x, onehot(y, num_classes)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a = onehot(y, num_classes)\n",
    "    y_b = onehot(y[index], num_classes)\n",
    "    mixed_y = lam * y_a + (1 - lam) * y_b\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "def rand_bbox(W, H, lam):\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_batch(x, y, alpha=1.0, num_classes=NUM_CLASSES):\n",
    "    if alpha <= 0:\n",
    "        return x, onehot(y, num_classes)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size, C, H, W = x.size()\n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(W, H, lam)\n",
    "    x_cut = x.clone()\n",
    "    x_cut[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    lam_adjusted = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "\n",
    "    y_a = onehot(y, num_classes)\n",
    "    y_b = onehot(y[index], num_classes)\n",
    "    mixed_y = lam_adjusted * y_a + (1 - lam_adjusted) * y_b\n",
    "    return x_cut, mixed_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9259d8-546c-4533-a669-c5b3b9c83f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 3. ResNet-50 생성 함수\n",
    "#############################################\n",
    "\n",
    "def create_resnet50(num_classes=NUM_CLASSES):\n",
    "    # pretrained 안 쓰고 빈 ResNet50로 시작 (조금 더 가벼움)\n",
    "    resnet50 = models.resnet50(weights=None)\n",
    "    in_features = resnet50.fc.in_features\n",
    "    resnet50.fc = nn.Linear(in_features, num_classes)\n",
    "    return resnet50\n",
    "\n",
    "criterion_sparse = nn.CrossEntropyLoss()  # 정수 라벨용 (No Aug, Basic Aug에서 사용)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0f6d5f-3b57-4310-a3ab-c490ae179d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 4. Train / Eval 함수\n",
    "#############################################\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer,\n",
    "                    use_mixup=False, use_cutmix=False,\n",
    "                    alpha=1.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ---- 여기서 MixUp / CutMix 적용 여부 결정 ----\n",
    "        if use_mixup:\n",
    "            inputs, targets = mixup_batch(images, labels, alpha=alpha)\n",
    "            outputs = model(inputs)\n",
    "            loss = categorical_crossentropy(outputs, targets)\n",
    "        elif use_cutmix:\n",
    "            inputs, targets = cutmix_batch(images, labels, alpha=alpha)\n",
    "            outputs = model(inputs)\n",
    "            loss = categorical_crossentropy(outputs, targets)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion_sparse(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "\n",
    "        # 정확도는 항상 \"원래 정수 라벨\" 기준으로 계산\n",
    "        _, preds = outputs.max(1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    return running_loss / total, running_correct / total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion_sparse(outputs, labels)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            total += batch_size\n",
    "\n",
    "    return running_loss / total, running_correct / total\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader,\n",
    "                epochs, use_mixup=False, use_cutmix=False,\n",
    "                alpha=1.0, tag=\"\"):\n",
    "    history = {\"train_loss\": [], \"train_acc\": [],\n",
    "               \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer,\n",
    "            use_mixup=use_mixup, use_cutmix=use_cutmix, alpha=alpha\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"[{tag}] Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528959ea-5c9c-4efa-bab3-f2f5a4f5a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== NoAug 학습 시작 =====\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 5. 네 가지 경우를 \"순서대로\" 학습\n",
    "#############################################\n",
    "\n",
    "histories = {}  # 각 실험의 history 저장\n",
    "\n",
    "experiments = [\n",
    "    (\"NoAug\",        train_loader_noaug,  False, False),  # (이름, train_loader, use_mixup, use_cutmix)\n",
    "    (\"BasicAug\",     train_loader_basic,  False, False),\n",
    "    (\"Basic+MixUp\",  train_loader_basic,  True,  False),\n",
    "    (\"Basic+CutMix\", train_loader_basic,  False, True),\n",
    "]\n",
    "\n",
    "for name, train_loader, use_mixup, use_cutmix in experiments:\n",
    "    print(f\"\\n===== {name} 학습 시작 =====\")\n",
    "\n",
    "    model = create_resnet50().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    history = train_model(\n",
    "        model, optimizer,\n",
    "        train_loader, val_loader,\n",
    "        epochs=EPOCHS,\n",
    "        use_mixup=use_mixup,\n",
    "        use_cutmix=use_cutmix,\n",
    "        alpha=1.0,\n",
    "        tag=name\n",
    "    )\n",
    "\n",
    "    histories[name] = history\n",
    "\n",
    "    # CPU라서 굳이 비울 필요는 없지만 형식상\n",
    "    del model\n",
    "    del optimizer\n",
    "    print(f\"===== {name} 학습 종료 =====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae9067-7f0b-4ba7-af0f-06a55a82dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 6. 결과 시각화 & 최종 비교\n",
    "#############################################\n",
    "\n",
    "def plot_histories_from_dict(histories, metric=\"val_acc\"):\n",
    "    plt.figure()\n",
    "    for name, hist in histories.items():\n",
    "        plt.plot(hist[metric], marker=\"o\", label=name)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(metric)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 검증 정확도 곡선 비교\n",
    "plot_histories_from_dict(histories, metric=\"val_acc\")\n",
    "\n",
    "# 검증 손실 곡선 비교\n",
    "plot_histories_from_dict(histories, metric=\"val_loss\")\n",
    "\n",
    "# 마지막 Epoch 기준 정확도 요약 출력\n",
    "print(\"\\n=== 최종 Val Acc 비교 ===\")\n",
    "for name, hist in histories.items():\n",
    "    print(f\"{name}: {hist['val_acc'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a5ff7-6b46-42c6-95ed-0a95c822d3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d2f52-9726-40c4-8959-facb0caa0166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916254f9-567e-493d-b77d-4eaf5bd2f372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981020d-de0e-44c1-9962-7a1f0557afd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c044a31-e32c-467c-b6d8-ee6b94320db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7515b8-4314-4570-89ba-6ff9d61ad6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60c9f2-b30c-4f21-ac30-9ea2dbf9b233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce211cb1-254e-4f42-9f8d-494ac41f2d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37076c-7238-4cbe-bbb3-519a059ad85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092d831-767f-412d-bb3e-7b151f666e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60dceed-7d0c-4605-8c69-2635faa7c86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159eb53-9ef8-4bd3-8629-45667aeef6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bec59-d9d8-4ee1-af45-66494ca27051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ceb4a4-4620-4f6f-918a-b22c7a267a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

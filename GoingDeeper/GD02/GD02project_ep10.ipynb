{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28bbfd6-8ed8-4689-a47c-7600a1d5a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정 & 하이퍼파라미터\n",
    "# ============================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "dataset_dir = \"~/work/data_augmentation/data/Images/\"\n",
    "\n",
    "BATCH_SIZE = 32   # GPU 여유에 따라 16 / 32 / 64 등으로 조정\n",
    "EPOCHS = 10        # 먼저 짧게 돌려보고, 필요하면 10~20으로 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fea036-257f-41d0-a7d4-6a7b44d4fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 개수: 120\n",
      "DataLoader ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================\n",
    "# 1. Dataset / DataLoader\n",
    "# ============================\n",
    "\n",
    "def normalize_and_resize_img():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "def augment():\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2),\n",
    "    ])\n",
    "\n",
    "# transform=None 으로 불러놓고, 나중에 transform을 주입하는 구조 (node4 스타일)\n",
    "full_dataset = ImageFolder(root=dataset_dir, transform=None)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.583 * total_size)  # node4랑 동일 비율\n",
    "test_size = total_size - train_size\n",
    "ds_train, ds_test = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "NUM_CLASSES = len(full_dataset.classes)\n",
    "print(\"클래스 개수:\", NUM_CLASSES)\n",
    "\n",
    "def apply_normalize_on_dataset(dataset, is_test=False, batch_size=16, with_aug=False):\n",
    "    base_transform = normalize_and_resize_img()\n",
    "    if (not is_test) and with_aug:\n",
    "        # augment + normalize 순서로 transform 구성\n",
    "        dataset.dataset.transform = transforms.Compose([\n",
    "            *augment().transforms,\n",
    "            *base_transform.transforms,\n",
    "        ])\n",
    "    else:\n",
    "        dataset.dataset.transform = base_transform\n",
    "\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=not is_test,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)\n",
    "    return loader\n",
    "\n",
    "# 기본 Aug가 들어간 train_loader, Aug 없는 val_loader\n",
    "train_loader = apply_normalize_on_dataset(ds_train,\n",
    "                                          is_test=False,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          with_aug=True)\n",
    "val_loader   = apply_normalize_on_dataset(ds_test,\n",
    "                                          is_test=True,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          with_aug=False)\n",
    "\n",
    "print(\"DataLoader ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad6fdfb-7bf7-4712-bd00-bc83be73b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2. MixUp / CutMix + Loss\n",
    "# ============================\n",
    "\n",
    "def onehot(labels, num_classes=NUM_CLASSES):\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        return torch.nn.functional.one_hot(labels, num_classes=num_classes).float()\n",
    "    else:\n",
    "        return torch.nn.functional.one_hot(torch.tensor(labels),\n",
    "                                           num_classes=num_classes).float()\n",
    "\n",
    "def categorical_crossentropy(logits, target_onehot):\n",
    "    \"\"\"\n",
    "    logits: (B, C), target_onehot: (B, C)\n",
    "    MixUp/CutMix 같이 soft label일 때 쓰는 loss\n",
    "    \"\"\"\n",
    "    log_probs = torch.log_softmax(logits, dim=1)\n",
    "    loss = -(target_onehot * log_probs).sum(dim=1).mean()\n",
    "    return loss\n",
    "\n",
    "def mixup_batch(x, y, alpha=1.0, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    x: (B, C, H, W), y: (B,)\n",
    "    \"\"\"\n",
    "    if alpha <= 0:\n",
    "        return x, onehot(y, num_classes)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a = onehot(y, num_classes)\n",
    "    y_b = onehot(y[index], num_classes)\n",
    "    mixed_y = lam * y_a + (1 - lam) * y_b\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "def rand_bbox(W, H, lam):\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_batch(x, y, alpha=1.0, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    x: (B, C, H, W), y: (B,)\n",
    "    \"\"\"\n",
    "    if alpha <= 0:\n",
    "        return x, onehot(y, num_classes)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size, C, H, W = x.size()\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(W, H, lam)\n",
    "    x_cut = x.clone()\n",
    "    x_cut[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
    "\n",
    "    lam_adjusted = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "\n",
    "    y_a = onehot(y, num_classes)\n",
    "    y_b = onehot(y[index], num_classes)\n",
    "    mixed_y = lam_adjusted * y_a + (1 - lam_adjusted) * y_b\n",
    "    return x_cut, mixed_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024d359b-d29d-45d2-a172-64af7015ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. ResNet-50 세 개 만들기\n",
    "# ============================\n",
    "\n",
    "def create_resnet50(num_classes=NUM_CLASSES):\n",
    "    resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    in_features = resnet50.fc.in_features\n",
    "    resnet50.fc = nn.Linear(in_features, num_classes)  # 마지막 FC만 교체\n",
    "    return resnet50\n",
    "\n",
    "model_basic  = create_resnet50().to(device)  # 기본 Aug만\n",
    "model_mixup  = create_resnet50().to(device)  # MixUp\n",
    "model_cutmix = create_resnet50().to(device)  # CutMix\n",
    "\n",
    "optimizer_basic  = optim.SGD(model_basic.parameters(),  lr=0.001, momentum=0.9)\n",
    "optimizer_mixup  = optim.SGD(model_mixup.parameters(),  lr=0.001, momentum=0.9)\n",
    "optimizer_cutmix = optim.SGD(model_cutmix.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "criterion_sparse = nn.CrossEntropyLoss()  # 기존 sparse categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a543d56-f4c1-4f8e-9fd4-75c0b8d6e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. Train / Eval 함수\n",
    "# ============================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer,\n",
    "                    use_mixup=False, use_cutmix=False,\n",
    "                    alpha=1.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ---- 여기서 MixUp / CutMix 적용 ----\n",
    "        if use_mixup:\n",
    "            inputs, targets = mixup_batch(images, labels, alpha=alpha)\n",
    "            outputs = model(inputs)\n",
    "            loss = categorical_crossentropy(outputs, targets)\n",
    "        elif use_cutmix:\n",
    "            inputs, targets = cutmix_batch(images, labels, alpha=alpha)\n",
    "            outputs = model(inputs)\n",
    "            loss = categorical_crossentropy(outputs, targets)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion_sparse(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "\n",
    "        # 정확도는 \"원래 라벨\" 기준\n",
    "        _, preds = outputs.max(1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    return running_loss / total, running_correct / total\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion_sparse(outputs, labels)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            total += batch_size\n",
    "\n",
    "    return running_loss / total, running_correct / total\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader,\n",
    "                epochs, use_mixup=False, use_cutmix=False,\n",
    "                alpha=1.0, tag=\"\"):\n",
    "    history = {\"train_loss\": [], \"train_acc\": [],\n",
    "               \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer,\n",
    "            use_mixup=use_mixup, use_cutmix=use_cutmix, alpha=alpha\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"[{tag}] Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc88da-9fb6-4e07-8380-51c90f8d0926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Basic] Epoch [1/10] Train Loss: 2.8184, Train Acc: 0.4931, Val Loss: 1.1508, Val Acc: 0.7708\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 5. 실제 학습 (루브릭용 3모델 비교)\n",
    "# ============================\n",
    "\n",
    "history_basic = train_model(model_basic, optimizer_basic,\n",
    "                            train_loader, val_loader,\n",
    "                            epochs=EPOCHS,\n",
    "                            use_mixup=False, use_cutmix=False,\n",
    "                            tag=\"Basic\")\n",
    "\n",
    "history_mixup = train_model(model_mixup, optimizer_mixup,\n",
    "                            train_loader, val_loader,\n",
    "                            epochs=EPOCHS,\n",
    "                            use_mixup=True, use_cutmix=False,\n",
    "                            alpha=1.0,\n",
    "                            tag=\"MixUp\")\n",
    "\n",
    "history_cutmix = train_model(model_cutmix, optimizer_cutmix,\n",
    "                             train_loader, val_loader,\n",
    "                             epochs=EPOCHS,\n",
    "                             use_mixup=False, use_cutmix=True,\n",
    "                             alpha=1.0,\n",
    "                             tag=\"CutMix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c424a7-7caa-4acc-8c8f-aac8e11fb7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# 6. 결과 시각화 (루브릭 3번)\n",
    "# ============================\n",
    "\n",
    "def plot_histories(histories, labels, metric=\"val_acc\"):\n",
    "    plt.figure()\n",
    "    for hist, lab in zip(histories, labels):\n",
    "        plt.plot(hist[metric], marker=\"o\", label=lab)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(metric)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_histories(\n",
    "    [history_basic, history_mixup, history_cutmix],\n",
    "    [\"Basic\", \"MixUp\", \"CutMix\"],\n",
    "    metric=\"val_acc\"\n",
    ")\n",
    "\n",
    "plot_histories(\n",
    "    [history_basic, history_mixup, history_cutmix],\n",
    "    [\"Basic\", \"MixUp\", \"CutMix\"],\n",
    "    metric=\"val_loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8f52b-3b30-4a1d-8572-21effad4d5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea14325-6656-4da5-9a53-f86773ab9f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6b8fd-77ad-45e9-beb4-98431fb945ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d1315-752c-433d-b173-bb3380c9aa88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff31a3-714c-4af8-b4fd-9468a52ea084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a956a-7bc9-4ac5-9f0e-26121831ca27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c168728-d6bb-48d4-9fc3-614320896322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befe8ef-c30f-4970-83af-40f4ad5cca03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a16647-78cb-4c85-be15-33023ce2000f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33991c-bbfc-401b-9f01-811c3a74f132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7666aba-8bcc-4e67-aaee-82a64e8513c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff9dbc-1a9e-407d-b943-483be335d263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f2d30-6a18-4ceb-a24a-08ffb260b83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca7694-568d-4b42-ba01-9a7d5fa6a397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ae423-a413-414e-9e49-6e52a50119f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb71c74-23d6-48a5-a828-07669523564b",
   "metadata": {},
   "source": [
    "프로젝트: Mixup 또는 CutMix 비교실험 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54467b36-4627-4b2c-bb47-36751bd5ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n",
      "2.2.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c640456-7eb0-4816-9c6c-21d00128040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e99693a-fb5a-42aa-85ae-38ce9153b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 1. 전처리 & 기본 Augmentation + DataLoader 함수\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def base_transform():\n",
    "    \"\"\"Resize + ToTensor + Normalize만 포함된 기본 전처리\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "def augment_transform():\n",
    "    \"\"\"기본 Augmentation (좌우반전 + 밝기 조절)\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2)\n",
    "    ])\n",
    "\n",
    "def apply_normalize_on_dataset(dataset,\n",
    "                               is_test=False,\n",
    "                               batch_size=32,\n",
    "                               with_aug=False):\n",
    "    \"\"\"\n",
    "    - normalize, resize, (옵션) augmentation, shuffle 적용\n",
    "    - is_test=True : augmentation X, shuffle X\n",
    "    \"\"\"\n",
    "    # Subset 인 경우를 고려해 실제 dataset과 indices 분리\n",
    "    if isinstance(dataset, torch.utils.data.Subset):\n",
    "        raw_dataset = dataset.dataset\n",
    "        indices = dataset.indices\n",
    "    else:\n",
    "        raw_dataset = dataset\n",
    "        indices = None\n",
    "\n",
    "    tf_list = []\n",
    "    if with_aug and not is_test:\n",
    "        tf_list.append(augment_transform())\n",
    "    tf_list.append(base_transform())\n",
    "    transform = transforms.Compose(tf_list)\n",
    "\n",
    "    raw_dataset.transform = transform\n",
    "\n",
    "    if indices is not None:\n",
    "        dataset = torch.utils.data.Subset(raw_dataset, indices)\n",
    "    else:\n",
    "        dataset = raw_dataset\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=not is_test,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e4f210-834c-44d2-b8fc-0a6d0915aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 2. Mixup & CutMix 유틸 함수 + soft CE\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def onehot(labels, num_classes):\n",
    "    return F.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0.0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"CutMix용 bbox 생성\"\"\"\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # 중앙 좌표 샘플링\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    if alpha > 0.0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.0\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    shuffled_x = x[index]\n",
    "    shuffled_y = y[index]\n",
    "\n",
    "    x1, y1, x2, y2 = rand_bbox(x.size(), lam)\n",
    "    new_x = x.clone()\n",
    "    new_x[:, :, y1:y2, x1:x2] = shuffled_x[:, :, y1:y2, x1:x2]\n",
    "\n",
    "    # 실제 lam은 박스 면적 비율로 다시 조정\n",
    "    box_area = (x2 - x1) * (y2 - y1)\n",
    "    lam = 1.0 - box_area / (x.size(2) * x.size(3))\n",
    "\n",
    "    y_a, y_b = y, shuffled_y\n",
    "    return new_x, y_a, y_b, lam\n",
    "\n",
    "def soft_cross_entropy(pred, target):\n",
    "    \"\"\"\n",
    "    categorical_crossentropy에 해당 (soft-label용)\n",
    "    pred : (B, C) logits\n",
    "    target : (B, C) one-hot 또는 soft label\n",
    "    \"\"\"\n",
    "    log_probs = F.log_softmax(pred, dim=1)\n",
    "    loss = -(target * log_probs).sum(dim=1).mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fcc8ae-72cf-43bb-ab3e-569c3242c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 3. ResNet-50 모델 생성 함수\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def create_resnet50(num_classes):\n",
    "    model = models.resnet50(weights=None)    # 필요하면 pretrained으로 변경 가능\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e088a68-ac3a-4948-9bb3-b537eb51bdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 120\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 4. 데이터셋 준비\n",
    "# ----------------------------------------------------\n",
    "\n",
    "dataset_dir = \"~/work/data_augmentation/data/Images/\"\n",
    "full_dataset = ImageFolder(root=dataset_dir, transform=base_transform())\n",
    "\n",
    "num_classes = len(full_dataset.classes)\n",
    "print(\"num_classes:\", num_classes)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size   = total_size - train_size\n",
    "ds_train, ds_val = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader (기본 Aug / 검증)\n",
    "train_loader_baseline = apply_normalize_on_dataset(\n",
    "    ds_train, is_test=False, batch_size=32, with_aug=True\n",
    ")\n",
    "val_loader = apply_normalize_on_dataset(\n",
    "    ds_val, is_test=True, batch_size=32, with_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb8e1a4-e132-45ea-bfa6-90767c7ad7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 5. 학습 루프 (baseline / mixup / cutmix 공통)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                num_epochs=5,\n",
    "                mode=\"baseline\",\n",
    "                alpha=1.0):\n",
    "\n",
    "    \"\"\"\n",
    "    mode:\n",
    "      - \"baseline\" : 기본 augmentation만 사용\n",
    "      - \"mixup\"    : Mixup 적용\n",
    "      - \"cutmix\"   : CutMix 적용\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion_plain = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_accuracy\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if mode == \"mixup\":\n",
    "                # Mixup → soft label + categorical_crossentropy\n",
    "                mixed_x, y_a, y_b, lam = mixup_data(images, labels, alpha)\n",
    "                y_a = onehot(y_a, num_classes).to(device)\n",
    "                y_b = onehot(y_b, num_classes).to(device)\n",
    "\n",
    "                outputs = model(mixed_x)\n",
    "                loss = lam * soft_cross_entropy(outputs, y_a) + \\\n",
    "                       (1 - lam) * soft_cross_entropy(outputs, y_b)\n",
    "\n",
    "            elif mode == \"cutmix\":\n",
    "                # CutMix → soft label + categorical_crossentropy\n",
    "                mixed_x, y_a, y_b, lam = cutmix_data(images, labels, alpha)\n",
    "                y_a = onehot(y_a, num_classes).to(device)\n",
    "                y_b = onehot(y_b, num_classes).to(device)\n",
    "\n",
    "                outputs = model(mixed_x)\n",
    "                loss = lam * soft_cross_entropy(outputs, y_a) + \\\n",
    "                       (1 - lam) * soft_cross_entropy(outputs, y_b)\n",
    "\n",
    "            else:\n",
    "                # baseline : 일반 CrossEntropy (sparse_categorical_crossentropy)\n",
    "                outputs = model(images)\n",
    "                loss = criterion_plain(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # ---------- 검증 ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                # 검증은 공통적으로 sparse CE 사용 (hard label)\n",
    "                loss = criterion_plain(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct / total\n",
    "\n",
    "        history[\"train_loss\"].append(epoch_train_loss)\n",
    "        history[\"val_loss\"].append(epoch_val_loss)\n",
    "        history[\"val_accuracy\"].append(epoch_val_acc)\n",
    "\n",
    "        print(f\"[{mode}][Epoch {epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f} | \"\n",
    "              f\"Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b65ec-efa9-4d28-b31c-9cca8e814221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 7. 결과 시각화 (루브릭용 비교 그래프)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def plot_histories(hist_base, hist_mix, hist_cut):\n",
    "    epochs = range(1, len(hist_base[\"val_accuracy\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, hist_base[\"val_accuracy\"], 'r-', label='Baseline Aug')\n",
    "    plt.plot(epochs, hist_mix[\"val_accuracy\"],  'b-', label='Mixup')\n",
    "    plt.plot(epochs, hist_cut[\"val_accuracy\"],  'g-', label='CutMix')\n",
    "    plt.title('Model validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_histories(hist_baseline, hist_mixup, hist_cutmix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ede76-de56-4fcd-aa57-988103cf2dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d47688-d86f-4478-b794-097345c9a7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca0544-fbed-46b3-b717-803781a043a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c639a-2f65-467f-8aff-945f629e10b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
